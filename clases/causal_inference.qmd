---
title: "Inferencia causal"
author: "Carlos Ortiz"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(stargazer)
library(tidysynth)
library(ggplot2)
```

## Resultados potenciales

El problema de evaluación consiste en medir el impacto del programa (o tratamiento) sobre un conjunto de variables de resultado en un conjunto de individuos. Por ejempmlo, el efecto que tiene un programa de nutrición en los indicadores antropométricos. Se busca establecer la diferencia entre la variable de resultado del individuo participante en el programa en presencia del programa y la variable de resultado de ese individuo en ausencia del programa. Esta diferencia es lo que se conoce como efecto del tratamiento o programa.

> El problema fundamental de la evaluación de impacto es que no podemos ver ambos resultados en el mismo individuo.

El marco teórico estándar para formalizar el problema de la evaluación de impacto se basa en el modelo de *resultado potencial*. Formalmente, se puede definir el indicador de tratamiento como $D_i$. En un escenario de tratamiento binario (recibe o no recibe), $D_i=1$ si lo recibe y $D_i=0$ si no lo recibe. Las variables de resultado se pueden definir como $Y_i(D_i)$ para cada individuo $i=1,...,N$. Es decir, $Y_i(1)$ es la variable de resultado si el individuo $i$ es tratado y $Y_i(0)$ es la variable de resultado si el individuo $i$ no es tratado. El efecto del tratamiento para un individuo $i$ se puede escribir como:

$$\tau_i=Y_i(1)-Y_i(0)$$
Volviendo al problema fundamental de la evaluación de impacto se tendrá un resultado excluyente

$$Y_i=D_iY_i(1)+(1-D_i)Y_i(0)=\begin{cases}
Y_i(1) &\text{ si }D_i=1\\
Y_i(0) &\text{ si }D_i=0
\end{cases}$$

Debido a que uno de los dos resultados no se puede observar, debemos concentrarnos en el impacto promedio, el efecto medio de tratamiento o ATE:

$$\tau_{ATE}=\mathbb{E}(\tau_i)=\mathbb{E}[Y_i(1)-Y_i(0)]$$
Una representación simple a través de una regresión lineal de esto puede ser de la forma

$$Y_i=\beta_0+\tau_iD_i + u_i$$
En la mayoría de los casos, el tratamiento o programa no es universal sino que sólo está disponible para un subconjunto de la polbación, generalmente porque el programa ha sido focalizado. En este caso, es posible utilizar un estimador que únicamente promedie el efecto sobre la población elegible. Se puede utilizar el impacto sobre los tratados o ATT:

$$\tau_{ATT}=\mathbb{E}[\tau_i|D_i=1]=\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=1]$$
El primer término es el valor esperado de resultado en el grupo de tratamiento en presencia del tratamiento y el segundo que se conoce como resultado contrafactual, es el valor esperado de la variable resultado en el grupo de tratamiento en ausencia del tratamiento. Esto puede hacerse también pero con aquellos que no son tratados o ATU:

$$\tau_{ATU}=\mathbb{E}[\tau_i|D_i=0]=\mathbb{E}[Y_i(1)|D_i=0]-\mathbb{E}[Y_i(0)|D_i=0]$$
En cualquiera de los casos es necesario escoger una aproximación plausible del contrafactual. Si nos enfocamos en $\tau_{ATT}$, una aproximación plausible para $\mathbb{E}[Y_i(0)|D_i=1]$ puede ser el grupo de control $\mathbb{E}[Y_i(0)|D_i=0]$. Esta comparación podría generar estimaciones inexactas ya que los participantes y no participantes del programa suelen ser diferentes incluso en ausencia del programa. Este problema se conoce como sesgo de selección. Se tiene la siguiente comparación entre participantes y no participantes:

$$\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]$$
Y se tiene el $\tau_{ATT}$
$$\tau_{ATT}=\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=1]$$
$$\tau_{ATT}+\mathbb{E}[Y_i(0)|D_i=1]=\mathbb{E}[Y_i(1)|D_i=1]$$
Si se resta a ambos lados $\mathbb{E}[Y_i(0)|D_i=0]$ se tiene

$$\tau_{ATT}+\mathbb{E}[Y_i(0)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]=\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]$$
Y se deriva que la aproximación del $\tau_{ATT}$, $\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]$ se puede utilizar si y solo si $\mathbb{E}[Y_i(0)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]=0$.

En este caso 

$$\tau_{ATT}=\mathbb{E}[Y_i(1)|D_i=1]-\mathbb{E}[Y_i(0)|D_i=0]$$
El estimador vendría dado por el análogo muestral

$$\hat{\tau}_{ATT}=(\bar{Y}|D_i=1)-(\bar{Y}|D_i=0)$$
El estimador del efecto del programa bajo el supuesto de que no existe sesgo de selección resulta de comaprar el promedio muestral de $Y$ en el grupo de tratamiento con el promedio muestral de $Y$ en el grupo de control. Esta comparación de medias se puede implementar fácilmente por el método de regresión de la siguiente manera

$$Y_i=\beta_0+\beta_1D_i+u_i$$
La participación en el programa es independiente de las características del individuo, por tanto

$$\mathbb{E}[u_i|D_i]=0$$
Esto se conoce como el supuesto de independencia condicional. Bajo este supuesto el estimador de MCO es consistente e insesgado.

$$\mathbb{E}[Y_i(1)|D_i=1]=\mathbb{E}[\beta_0+\beta_1+u_i|D_i=1]=\beta_0+\beta_1$$
$$\mathbb{E}[Y_i(1)|D_i=0]=\mathbb{E}[\beta_0+u_i|D_i=1]=\beta_0$$
El estimador de $\beta_1$ vendría dado por

$$\hat{\beta}_1=(\bar{Y}|D_i=1)-(\bar{Y}|D_i=0)$$

## Regresión discontinua

> Algunos diseños no experimentales de asignación de política pública proveen fuentes de variación del tratamiento que pueden ser explotadas para estimar el efecto del tratamiento bajo supuestos relativamente débiles. (Peña & Bernal, 2022)

Una de estas situaciones es cuando la probabilidad de participar en un tratamiento cambia discontinuamente con una variable continua observada $Z$. Esto ocurre en el contexto de la política pública que busca focalizar un grupo particular. La asignación del tratamiento se determina con base en un umbral de $Z$, que denominamos $\bar{Z}$, que determina la elegibilidad para el programa.

Para cada individuo $i$ observamos el indicador de tratamiento, $D_i$, la variable de resultado, $Y_i$, una serie de características observables que no dependen directamente del tratamiento pero afectan la variable de resultado, $X_i$, y una variable observable, $Z_i$, que es una variable continua de focalización que determina la elegibilidad para el programa dependiendo de si suvalor es mayor o menor que un determinado umbral fijo, $\bar{Z}$. 

La intuición de Regresión Discontinua es que los individuos justamente a la izquierda del umbral deben ser muy parecidos a los individuos justamente a la derecha del umbral, excepto que los primeros participan en el programa y los segundos no. Por tal motivo, los últimos podrían ser un contrafactual válido de los primeros.

### Regresión discontinua nítida

Este diseño ocurre cuando $Z$ determina completamente la participación en el programa sobre la base de un umbral $\bar{Z}$. 

$$
D_i(Z_i))I[Z_i\leq \bar{Z}]
$$

donde $I[*]=1$ si la condición $*$ se cumple y cero de lo contrario. El diseño nítido implica que el proceso de decisión exógeno es completamente determinado por $Z$. Esto se puede observar en el siguiente gráfico.

```{r}
z <- 1:10
y0 <- rep(0, 10)
y1 <- rep(1, 10)

ggplot() +
   geom_line(aes(z[1:5], y0[1:5])) +
  geom_line(aes(z[5:10], y1[5:10])) +
  
   labs(x = "Score", y = "Probababilidad de participación") +
  geom_vline(xintercept = 5, linetype = 'dashed') +
   theme_minimal()


```

La condición de **identificación** de RDN se puede escribir formalmente como 

$$
\lim_{z\uparrow \bar{Z}}D(Z=z)\neq \lim_{z\downarrow\bar{Z}}D(Z=z)
$$
El límite del indicador de tratamiento, $D(Z=z)$, a medida que $z$ tiende a $\bar{Z}$, es diferente dependiendo de si se acerca por la izquierda o por la derecha. La principal fuente de identificación en RDN es la discontinuidad en la participación en el tratamiento en un punto específico de la distribución de $Z$.
```{r}
z <- 0:10
y0 <- 6 + 0.2 * z
y1 <- 4 + 0.2 * z

ggplot() +
   geom_line(aes(z[1:6], y0[1:6])) +
  geom_line(aes(z[6:11], y1[6:11])) +
  geom_line(aes(z[6:11], y0[6:11]), linetype = 'dashed', alpha = 0.4) +
  geom_line(aes(z[1:6], y1[1:6]), linetype = 'dashed', alpha = 0.4) +
  
  
   labs(x = "Score", y = "Variable de resultado") +
  geom_vline(xintercept = 5, linetype = 'dashed', ) +
   theme_minimal()
```
La expectativa condicional de la variable de resultado observada está dada por:

$$
E[Y|Z=z]=E[Y|D=0, z]P(D=0|Z=z)+E[Y|D=1, Z=z]P(D=1|Z=z)
$$

Esto corresponde a la totalidad de la línea sólida en la gráfica anterior. La expectativa condicional de la variable de resultado observada no es continua sino que salta en $Z=\bar{Z}$. Este diseño nítido implica que el proceso de decisión exógeno es completamente determinado por $Z$. 

### Supuesto de continuidad

El diseño implica que los individuos están en alguno de los dos lados del umbral. Por tanto, no existen individuos con $Z_i=\bar{Z}$ para los cuales se observe $Y_i(0)$ porque todos los individuos localizados en el umbral $\bar{Z}$ participan en el programa. Sin embargo, se pueden utilizar individuos no participantes con valores de $Z$ arbitrariamente cercanos a $\bar{Z}$ para calcular el efecto del tratamiento, si esos individuos son similares a los participantes.

Esto requiere de un supuesto adicional: continuidad. Formalmente, RD requiere que $E[Y(0)|Z=z]$ y $E[Y(1)|Z=z]$ sean continuas en $\bar{Z}$, para garantizar que la información del lado no tratado del umbral $\bar{Z}$ constituya un contrafactual válido para el lado tratado del umbral (continuidad local):

$$
\lim_{z\uparrow \bar{Z}}E[Y(0)|Z=z]=\lim_{z\downarrow\bar{Z}}E[Y(0)|Z=z]
$$
$$
\lim_{z\uparrow \bar{Z}}E[Y(1)|Z=z]=\lim_{z\downarrow\bar{Z}}E[Y(1)|Z=z]
$$
Esto implica que no existen discontinuidades en $\bar{Z}$ en la relación entre la variable de resultado $Y$ y las variables $X$ que la determinan: los individuos a ambos lados del umbral son similares. No se quieren discontinuidades con las variables predictoras alrededor del umbral.

Adcionalmente, se tiene el supuesto de no manipulación: no hay un salto en la función de densidad del instrumento $Z$ en el umbral $\bar{Z}$. Podemos ver este último en el siguiente gráfico de Baez et. al (2012).

![Discontinuidades en la función de densidad]()


```{r}
dat <- tibble(
  x = rnorm(1000, 50, 25)
) |> mutate (
  x = if_else(x <0, 0, x) 
) |> filter(x < 100)

dat <- dat |> mutate(
  D = if_else(x > 50, 1, 0),
  y1 = 25 + 0 * D + 1.5 * x+ rnorm(n(), 0, 20)
)

ggplot(aes(x, y1, colour=factor(D)), data = dat) +
  geom_point(alpha = 0.5) + 
  geom_vline(xintercept = 50, colour = "grey", linetype=2) + 
  stat_smooth(method = "lm", se = F) +
  labs(x = "Test score (X)", y = "Potential Outcome (Y1)") +
  theme_minimal()
```

Simulación de discontinuidad

```{r}
dat <- dat |>
  mutate(
    y2 = 25 + 40 * D + 1.5 * x + rnorm(n(), 0, 20) 
  )

ggplot(aes(x, y2, colour = factor(D)), data = dat) + 
  geom_point(alpha = 0.5) +
  geom_vline(xintercept = 50, colour = "grey", linetype = 2) +
  stat_smooth(method = "lm", se = F) + 
  labs(x = "Test score (X)", y = "Potential outcome (Y)")+
  theme_minimal()
```


Simulación de no linealidad

```{r}
dat <- tibble(
  x = rnorm(1000, 100, 50)
) |>
  mutate(
    x = case_when(x < 0 ~ 0, TRUE ~ x),
    D = case_when(x > 140 ~ 1, TRUE ~ 0),
    x2 = x*x,
    x3 = x*x*x,
    y3 = 10000 + 0 *D -100 * x + x2 + rnorm(1000, 0, 1000)
  ) |> filter (x < 280)

ggplot(aes(x, y3, colour = factor(D)), data = dat) +
  geom_point(alpha = 0.2) + 
  geom_vline(xintercept = 140, colour = "grey", linetype = 2) + 
  stat_smooth(method = "lm", se = F) +
  labs(x = "Test score (X)", y = "Potential Outcome (Y)")

ggplot(aes(x, y3, colour = factor(D)), data = dat) + 
  geom_point(alpha = 0.2) + 
  geom_vline(xintercept = 140, colour = "grey", linetype = 2) +
  stat_smooth(method = "loess", se = F) + 
  labs(x = "Test score (X)", y = "Potential Outcome (Y)") +
  theme_minimal()
```


Simulación ajustando la función 

```{r}
dat <- tibble(
  x = rnorm(1000, 100, 50)
) |> mutate(
  x = case_when(x < 0 ~ 0, TRUE ~ x),
  D = case_when(x > 140 ~ 1, TRUE ~ 0),
  x2 = x*x,
  x3 = x*x*x,
  y3 = 10000 + 0 * D - 100 * x + x2 + rnorm(1000, 0, 1000)
) |> filter (x < 280)

regression <- lm(y3 ~D*., data = dat)

stargazer(regression, type = "text")

ggplot(aes(x, y3, colour=factor(D)), data = dat) + 
  geom_point(alpha = 0.2) + 
  geom_vline(xintercept = 140, colour = "grey", linetype = 2) + 
  stat_smooth(method = "lm", se = F) +
  labs(x = "Test score (X)", y = "Potential Outcome (Y)") + 
  theme_minimal()

```


### Identificación

### Supuestos

### Estimación 

### Ejemplos

### Bibliografía

Thistelhwaite, Campbell (1960)

Van Der Klaauw (2002)

Cook (2008)

Angrist, Lavy (1999)

Black (1999)

Hahn (2001)

Hansen (2015)

Hoekstra (2009)

Card (2008)

Almond et al (2010)

Barreca (2011)

Jacob, Lefgen (2004)



## Diferencias en diferencias

## Control sintético 

Este método provee de ventajas sustanciales como diseño de investigación en las ciencias sociales.

> "arguably the most important innovation in the policy evaluation literature in the last 14 years" (Athey and Imbens, 2017)

Considere un problema en donde una unidad agregada, como una ciudad o un departamento, es expuesto a un evento o intervención de interés (programa de control de tabaco en California (Abadie et. al, 2010) o efecto de un programa educativo en el distrito educativo de Syracuse, New York (Bifulco et. al, 2017)). La mayoría de las técnicas de análisis de regresión requieren de muestras grandes y muchas observaciones. Los economistas han empleado métodos provenientes de las series de tiempo y estudios comparativos para entender los efectos sobre grandes agregados. No obstante, esto permite observar los efectos de shocks en el corto plazo (impulso respuesta), más no permite observar los efectos de largo plazo.

El método de control sintético se basa en la idea de que, cuando las unidades de observación son un número pequeño de unidades agregadas, una combinación de las unidades no afectas por el tratamiento puede proveer una mejor comparación que cualquier unidad no afectada por sí sola. 

### The setting

1. Se tienen datos para $J + 1$ unidades. 
2. La primera unidad $j=1$ es la unidad tratada y el resto son unidades no tratadas, y se consideran el "pool de donantes".
3. Los datos se expanden por $T$ periodos y los primeros periodos $T_0$ son pre-tratamiento.
4. Para cada unidad $j$ se observa tanto la variable de interés $Y_{jt}$ como las variables predictoras $X_{1j},...,X_{kj}$. 
5. Estas variables predictoras no son afectadas por la intervención.
6. Los vectores de tamaño $k\times 1$ $\mathbf{X}_1,...,\mathbf{X}_{J+1}$ contienen los valores de llos predictores para las unidades $j=1,...,J+1$.
7. Se tiene la siguiente matriz que contiene los valores de los predictores para las $J$ unidades no tratadas:
$$
\mathbf{X}_0=[\mathbf{X}_2...\mathbf{X}_{J+1}]
$$
8. Para cada una de las unidades $j$ y periodo de tiempo $t$, se tiene $Y_{tj}^N$, el resultado potencial sin intervención. Para la unidad afectada por la intervención $j=1$, y periodo post-tratamiento, $t>T_0$, se define a $Y_{1t}^I$ como el resultado potencial bajo la intervención. El efecto del tratamiento de interés para la unidad afectada en el periodo $t$ (con $t>T_0$) es:

$$
\tau_{1t}=Y_{1t}^I-Y_{1t}^N
$$
Debido a que la unidad $j=1$ es expuesta al tratamiento después del periodo $T_0$, para $t>T_0$ se tiene que $Y_{1t}=Y_{1t}^I$. 

El reto está en estimar $Y_{1t}^N$ para $t>T_0$: cómo el resultado de interés habría evolucionado para la unidad afectada en ausencia del tratamiento. Esto es el resultado contrafactual. El efecto cambia en el tiempo.

### Estimación

Usualmente, para estimar $Y_{1t}^N$ se intenta reproducir a partir de una o varias unidades no afectas por el tratamiento con características similares a la unidad afectada al momento de la intervención. Cuando los datos consisten de pocas unidades, esto se puede tornar difícil. 

El control sintético entra a resolver el problema partiendo de la idea de que una combinación de unidades del pool de donantes puede aproximarse mejor a las características de la unidad afectada sustancialmente mejor que cualquier unidad no afectada. **Un control sintético es definido como un promedio ponderado de las unidades en el pool de donantes**.

Formalmente, un control sintético puede ser representado como un vector $J\times 1$ de pesos, $\mathbf{W}=(w_2, ...,w_{J+1})'$. Dado un conjunto de pesos , $\mathbf{W}$, los estimadores de $Y_{1t}^N$ y $\tau_{1t}$ son, respectivamente:

$$
\hat{Y}_{1t}^N=\sum_{j=2}^{J+1}w_jY_{jt}, \hspace{0.5cm}\hat{\tau}_{1t}=Y_{1t}-\hat{Y}_{1t}^N
$$
Para evitar extrapolación (overfitting), los pesos se restringen a que sean no negativos y que su suma de 1. Esto va a provocar, además, que no todos los donantes aporten para la construcción del control sintético. La pregunta que surge es ¿cómo deberían ser seleccionados o calculados estos pesos? Abadie et. al (2003) y Abadie et. al (2010) proponen:

> "Elegir $w_2,...,2_{J+1}$ de tal forma que el control sintético resultante se parezca lo más posible a los valores preintervención de las variables predictoras para la unidad tratada." 

Esto es, seleccionar $\mathbf{W}^*=(w_2^*,...,w_{J+1}^*)'$ que minimice

$$
||\mathbf{X}_1-\mathbf{X}_0\mathbf{W}|| = \left(\sum_{h=1}^kv_h(X_{h1}-w_2X_{h2}-...-w_{J+1}X_{hJ+1})^2\right)^{1/2}
$$
sujeto a que los pesos no sean negativos y que su suma sea 1. El efecto estimado del tratamiento para la unidad tratada en el tiempo $t=T_0+1,...,T$ es

$$
\hat{\tau}_{1t}=Y_{1t}-\sum_{j=2}^{J+1}w_j^*Y_{jt}
$$
Las constantes positivas $v_1,...,v_k$ reflejan la importancia relativa de los valores de cada una de las $k$ predictoras para la unidad tratada $X_{11},...,X_{k1}$ en el control sintético.



### Un ejemplo: Abadie et. al (2010)

La legislación antitabaco tiene una larga historia en Estados Unidos, pudiéndose ir hasta 1893, cuando Washington prohibió la venta de cigarrillos. En un principio, las motivaciones legales eran meramente morales y posteriormente de salud. En 1988, a partir de una iniciativa ciudadana, se propuso la "Proposition 99" a través de la cual se imponía un impuesto de 25 centavos sobre cada paquete de cigarrillo en el estado de California. El consumo se redujo, aunque podría ser muy optimista atribuirselo únicamente a la reforma. La pregunta es, como siempre, ¿Qué hubiera pasado con el consumo de cigarrillos en ausencia de la "Proposition 99"?

```{r}
data("smoking")

smoking |>
  dplyr::glimpse()
```

Veamos qué pasó.

```{r}
test <- smoking |> filter(state=="California")  |>
  select(c("year", "cigsale"))


ggplot(test, aes(x = year, y = cigsale)) +
  geom_line(color = "gray", size = 0.4) + 
  geom_point(color = "gray") + 
  geom_vline(xintercept = 1989, linetype = "longdash", color = "black") +
  labs(x = "year", y = "cigsale", title = "Time series of the observed cigsale") +
  theme_minimal()
  
```

El gráfico muestra una tendencia que puede hacernos pensar que con o sin "Proposition 99", las ventas de tabaco se habrían disminuido. ¿Tuvo algún impacto la "Proposition" o era mejor no gastar esos recursos? 

```{r}
smoking_out <-
  
  smoking %>%
  
  # initial the synthetic control object
  synthetic_control(outcome = cigsale, # variable de respuesta
                    unit = state, # unidad para el panel
                    time = year, # tiempo en el panel
                    i_unit = "California", # unidad tratada
                    i_time = 1988, # periodo de tratamiento
                    generate_placebos=T # generar placebos para la inferencia
                    ) %>%
  
  # Generar las variables para ajustar los pesos
  
  # log del ingreso promedio, precio retail de los cigarrillos, % población entre 15 - 24 años de 1980 a 1988

  generate_predictor(time_window = 1980:1988,
                     ln_income = mean(lnincome, na.rm = T),
                     ret_price = mean(retprice, na.rm = T),
                     youth = mean(age15to24, na.rm = T)) %>%
  
  # consumo promedio de cerveza del pool de donantes entre 1984 y 1988

  generate_predictor(time_window = 1984:1988,
                     beer_sales = mean(beer, na.rm = T)) %>%
  
  # rezagos de la venta de cigarrillos 
  generate_predictor(time_window = 1975,
                     cigsale_1975 = cigsale) %>%
  generate_predictor(time_window = 1980,
                     cigsale_1980 = cigsale) %>%
  generate_predictor(time_window = 1988,
                     cigsale_1988 = cigsale) %>%
  
  
  # generar los pesos
  generate_weights(optimization_window = 1970:1988, # periodo de tiempo para generar los pesos
                   margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6
  ) %>%
  
  # generar el control sintético
  generate_control()
```

Ahora ya podemos ver los resultados

```{r}
smoking_out %>% plot_trends()
```

Observe que el control sintético pre-tratamiento va muy de cerca al comportamiento de la variable de respuesta de la unidad tratada observada y justo después del tratamiento se abre. Esa diferencia entre el control y el tratamiento es el efecto de la "Proposition 99". Si calculamos la diferencia es aún más evidente. 

```{r}
smoking_out %>% plot_differences()
```

La diferencia va alrededor del 0 y cuando se aplica el tratamiento se observa una divergencia entre lo observado y el control sintético. Podemos observar también qué estados tuvieron mayor participación y qué variables tuvieron mayor relevancia.

```{r}
smoking_out %>% plot_weights()
```

Para después comparar qué tan parecido es, en las variables, el control sintético (la California de mentiras) con California y los otros estados:

```{r}
smoking_out %>% grab_balance_table()
```

### Inferencia

Abadie et. al (2010) proponen una forma de inferencia basada en métodos de permutación. En su versión más simple el efecto de la intervención es estimado separadamente para cada una de las unidades de la muestra. 

Considere el caso de una sola unidad. Se puede obtener una distribución de permutaciones al reasignar iterativamente el tratamiento a las unidades en el pool de donantes y estimar "efectos placebo" en cada iteración. El efecto del tratamiento en la undiad afecta por la intervención se puede decir que es significativa si su magnitud es relativamente extrema con respecto a la distribución de permutaciones. Observemos esos efectos placebo.

```{r}
smoking_out %>% plot_placebos(prune = FALSE)
```

Un problema con esto es que si bien algunos tienen un buen ajuste pre-tratamiento, esto no aplica para todos y pueden observarse casos muy extremos.

```{r}
smoking_out %>% plot_placebos()
```

Aquí podemos observar mejor el comportamiento. A partir de esto, Abadie et. al (2010) proponen una alternativa a través de un estadístico de prueba que mide el ratio del ajuste de post-intervención relativo al ajuste de pre-intervención. Para $0\leqt_1\leqt_2\leq T$ y %j=\{1,...,J+1\}$ se tiene

$$
R_j(t_1, t_2) = \left(\frac{1}{t_2-t_1+1}\sum_{t=t_1}^{t_2}\left(Y_{jt}-\hat{Y}_{jt}^N\right)^2\right)^{1/2}
$$

Esto se conoce como la raíz del error cuadrático medio de la predicción (RMSPE, por sus siglas en inglés) del estimador del control sintético para la unidad $j$ y periods $t_1,...,t_2$. Donde $\hat{Y}_{jt}^N$ es el outcome en el periodo $t$ generado por el control sintético cuando la unidad $j$ es la unidad tratada y utilizando el resto de las $J$ unidades para la construcción del pool de donantes.  El ratio entre el RMSPE post-tratamiento y el RMSPE pre-tratamiento para la unidad $j$ es 

$$
r_j=\frac{R_j(T_0+1, T)}{R_j(1, T_0)}
$$
$r_j$ mide la calidad del ajuste del control sintético para la unidad $j$ en el periodo post-tratamiento, relativo a la calidad del ajuste en el periodo pre-tratamiento. Como se vio, una alternativa es eliminar aquellos placebo que tienen un comportamiento sustancialmente mayor que la unidad de interés en pretratamiento. Aquí podemos ver el valor de los ratios.
```{r}
smoking_out %>% plot_mspe_ratio()
```

Un p-valor para el procedimiento de inferencia basado en la distribución de permutación de $r_j$ puede ser

$$
p = \frac{1}{J+1}\sum_{j=1}^{J+1}I_+(r_j-r_1)
$$
Donde $I_+(.)$ es una función indicador que devuelve uno para los argumentos no negativos y cero de otra forma.

```{r}
smoking_out %>% grab_significance()
```
Se puede observar que el ratio post/pre es mayor para California que para el resto. El p-valor es 0.02564103. No es producto del azar.

### Check-list antes de emplear control sintético

1. Tamaño del efecto (considerable) y volatilidad del resultado (filtros de suavizamiento).

2. Pool de donantes:
- No incluir unidades sometidas a tratamientos similares previamente a los de la unidad de interés.
- Eliminar aquellas que hayan enfrentado grandes shocks.
- Mantener unidades similares a la tratada.

3. No anticipación. No reaccionar anticipadamente al efecto de tratamiento (puede ajustarse).

4. No interferencia. No debe haber muchas consecuencias si el grupo de donantes cambia.

5. Horizonte de tiempo. Amplio hacia adelante y hacia atrás.

6. Se requiere el uso de datos agregados.

### Bibliografía



Abadie, Gardeazabal (2003)
Abadie et al (2010)
Athey, Imbens (2017)
Abadie et al (2015)
Abadie (2021)